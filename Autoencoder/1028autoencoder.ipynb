{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1028\n",
    "자동 인코더 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, UpSampling2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, _), (X_test, _) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(60000, 28*28)# Flatten 시킴\n",
    "X_test = X_test.reshape(10000, 28*28) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255 # Flatten 시킴\n",
    "X_test = X_test /255 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.models.Model): \n",
    "    def __int__(self, dim): \n",
    "        super(MyModel, self).__init__() \n",
    "        self.dim = dim \n",
    "        self.encoder = tf.keras.layers.Dense(dim)\n",
    "        self.decoder = tf.keras.layers.Dense(28*28, activation='sigmoid')   #activation은 0~1사이의 값으로 범위결정하는 애.\n",
    "    def call(self, input_): \n",
    "        x = self.encoder(input_)\n",
    "        x = self.decoder(x)\n",
    "        return x \n",
    "    \n",
    "    # def __call__(self): \n",
    "    #     builtd?  Call: build > call\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tf.keras.models.Model은 Multiinput, Multioutput이 된다.     \n",
    "-Sequntials를 한방향만 갈 수 있음     \n",
    "-모델안에 집어 넣을떄는 무조건 Sequential 쓴다 -> \"전처리 레이어를 모델의 일부로 사용하기\"에서 사용했다.     \n",
    "-계산복잡도를 줄일 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.models.Model): \n",
    "    def __int__(self, dim): \n",
    "        super(MyModel, self).__init__() \n",
    "        self.dim = dim \n",
    "        \n",
    "        # encoder 안에 여러개 동시에 실행해주는 model을 만들어야 함\n",
    "        #왜? Layers기 때문에 \n",
    "        self.encoder = tf.keras.models.Sequential([ \n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.Dense(dim, activation='relu')])  # 연산은 Dense에서 함 \n",
    "        # Flatten을 시키고, \n",
    "    #     self.encoder = tf.keras.layers.Dense(dim)\n",
    "    \n",
    "        self.decoder = tf.keras.models.Sequential([ #연산하는것이 아니고, 모양만 바꿔줌-> 그래서 위에 sigmoid 놓기 \n",
    "            tf.keras.layers.Dense(28*28, activation='sigmoid'),\n",
    "            tf.keras.layers.Reshape(28,28)\n",
    "        ]) \n",
    "       #self.decoder = tf.keras.layers.Dense(28*28, activation='sigmoid')   #activation은 0~1사이의 값으로 범위결정하는 애.\n",
    "    def call(self, input_): \n",
    "        x = self.encoder(input_)\n",
    "        x = self.decoder(x)\n",
    "        return x \n",
    "    \n",
    "  #  print(X_train.shape)\n",
    "  #  print(X_test.shape)\n",
    "    # def __call__(self): \n",
    "    #     builtd?  Call: build > call\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = MyModel(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 복잡하게 해서 만들경우 -> tf.keras.models.Model 사용하면 됨 \n",
    "- 상속을 통해 만들면 '객체지향'을 통해 더 유연한 모델만들기가 가능. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MyModel' object has no attribute 'encoder'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-179-ccc2a5865557>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mautoencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'MyModel' object has no attribute 'encoder'"
     ]
    }
   ],
   "source": [
    "autoencoder.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 60000\n  y sizes: 10000\nPlease provide data which shares the same first dimension.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-190-f3e4936ad060>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 자기 자신 학습\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mautoencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\www\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\www\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1061\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1062\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1063\u001b[1;33m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[0;32m   1064\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1065\u001b[0m       \u001b[1;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\www\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[0;32m   1115\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1117\u001b[1;33m         model=model)\n\u001b[0m\u001b[0;32m   1118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\www\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    280\u001b[0m             label, \", \".join(str(i.shape[0]) for i in nest.flatten(data)))\n\u001b[0;32m    281\u001b[0m       \u001b[0mmsg\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m\"Please provide data which shares the same first dimension.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 282\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    283\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 60000\n  y sizes: 10000\nPlease provide data which shares the same first dimension."
     ]
    }
   ],
   "source": [
    "# 자기 자신 학습 \n",
    "autoencoder.fit(X_train, X_test, batch_size=32, epochs=20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두번쨰\n",
    "(X_train, _), (X_test, _) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[..., tf.newaxis].shape \n",
    "tf.expand_dims(X_train, axis=-1)\n",
    "X_train = X_train.reshape(60000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.reshape(10000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = tf.keras.Input((28,28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.keras.layers.Conv2D(16,3, padding='same', activation='relu')(input_)\n",
    "# 중간에 Maxpooling 쓰자 \n",
    "x = tf.keras.layers.MaxPooling2D(2,2, padding='same')(x) \n",
    "\n",
    "x = tf.keras.layers.Conv2D(8,3, padding='same', activation='relu')(x)\n",
    "x = tf.keras.layers.MaxPooling2D(2,2, padding='same')(x) \n",
    "\n",
    "x = tf.keras.layers.Conv2D(8,3, padding='same', activation='relu')(x)\n",
    "x = tf.keras.layers.MaxPooling2D(2,2, padding='same')(x) \n",
    "\n",
    "x = tf.keras.layers.Conv2D(8,3, padding='same', activation='relu')(x)\n",
    "x = tf.keras.layers.UpSampling2D(size=(2,2))(x)\n",
    "x = tf.keras.layers.Conv2D(8,3, padding='same', activation='relu')(x)\n",
    "x = tf.keras.layers.UpSampling2D(size=(2,2))(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(16,3, padding='same', activation='relu')(x)\n",
    "# Pooling을 복원시키는 Unpooliing  \n",
    "x = tf.keras.layers.UpSampling2D(size=(2,2))(x)    #크기를 키운다. \n",
    "x = tf.keras.layers.Conv2D(16,3, padding='same', activation='relu')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tf.reshape(tf.range(24), (1,2,3,4))  # 4차원 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 2, 3, 4])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 6, 4), dtype=int32, numpy=\n",
       "array([[[[ 0,  1,  2,  3],\n",
       "         [ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11],\n",
       "         [ 8,  9, 10, 11]],\n",
       "\n",
       "        [[12, 13, 14, 15],\n",
       "         [12, 13, 14, 15],\n",
       "         [16, 17, 18, 19],\n",
       "         [16, 17, 18, 19],\n",
       "         [20, 21, 22, 23],\n",
       "         [20, 21, 22, 23]]]])>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.layers.UpSampling2D((1,2))(t) \n",
    "# 2,3 -> 2,6 으로 변했음. 크기만 변화시킨다\n",
    "# 1, , ,4  개수와 색상은 그대로. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 6, 6, 4), dtype=int32, numpy=\n",
       "array([[[[ 0,  1,  2,  3],\n",
       "         [ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11],\n",
       "         [ 8,  9, 10, 11]],\n",
       "\n",
       "        [[ 0,  1,  2,  3],\n",
       "         [ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11],\n",
       "         [ 8,  9, 10, 11]],\n",
       "\n",
       "        [[ 0,  1,  2,  3],\n",
       "         [ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11],\n",
       "         [ 8,  9, 10, 11]],\n",
       "\n",
       "        [[12, 13, 14, 15],\n",
       "         [12, 13, 14, 15],\n",
       "         [16, 17, 18, 19],\n",
       "         [16, 17, 18, 19],\n",
       "         [20, 21, 22, 23],\n",
       "         [20, 21, 22, 23]],\n",
       "\n",
       "        [[12, 13, 14, 15],\n",
       "         [12, 13, 14, 15],\n",
       "         [16, 17, 18, 19],\n",
       "         [16, 17, 18, 19],\n",
       "         [20, 21, 22, 23],\n",
       "         [20, 21, 22, 23]],\n",
       "\n",
       "        [[12, 13, 14, 15],\n",
       "         [12, 13, 14, 15],\n",
       "         [16, 17, 18, 19],\n",
       "         [16, 17, 18, 19],\n",
       "         [20, 21, 22, 23],\n",
       "         [20, 21, 22, 23]]]])>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.layers.UpSampling2D((3,2))(t) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tf.reshape(tf.range(12), (1,1,3,4))  # 4차원 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 3, 4), dtype=int32, numpy=\n",
       "array([[[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]]]])>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 1, 3, 4])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 6, 4), dtype=int32, numpy=\n",
       "array([[[[ 0,  1,  2,  3],\n",
       "         [ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11],\n",
       "         [ 8,  9, 10, 11]]]])>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.layers.UpSampling2D((1,2))(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 3, 4), dtype=int32, numpy=\n",
       "array([[[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]],\n",
       "\n",
       "        [[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]]]])>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.layers.UpSampling2D((2,1))(t)  # 위의 (1,2)와 (2,1)의 차이 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
